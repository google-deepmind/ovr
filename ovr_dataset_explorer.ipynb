{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlkPIDXOULip"
      },
      "source": [
        "#LICENSE\n",
        "\n",
        "Copyright 2024 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erNdJn93SMKt"
      },
      "source": [
        "# Pre-Requisities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vro1PdhdSPid"
      },
      "outputs": [],
      "source": [
        "# @title Install libraries\n",
        "!pip install --upgrade https://github.com/ytdl-org/youtube-dl/archive/master.zip --quiet\n",
        "\n",
        "!pip install mediapy ego4d awscli --quiet\n",
        "\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zd4WrnnSZ4D"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import json\n",
        "import os\n",
        "\n",
        "from typing import Any, List, Dict, Union\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mediapy as mpy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSriJ8cUxlk2"
      },
      "outputs": [],
      "source": [
        "# @title  Common Functions to both datasets\n",
        "\n",
        "def create_count_video(\n",
        "  frames: Union[List[np.ndarray], np.ndarray],\n",
        "  start: int,\n",
        "  end: int,\n",
        "  count: int,\n",
        "  desc: str,\n",
        "  output_file: str = \"/tmp/output.mp4\",) -\u003e None:\n",
        "  \"\"\"\n",
        "  Creates a video that displays a frame-by-frame count alongside the original\n",
        "  video frames.\n",
        "\n",
        "  Args:\n",
        "    frames: A list of numpy arrays representing the video frames.\n",
        "    start: The frame index where the count should start.\n",
        "    end: The frame index where the count should end.\n",
        "    count: The final count to be reached at the end frame.\n",
        "    desc: A description to be displayed on the video.\n",
        "    output_file: The path to save the output video. Defaults to\n",
        "    '/tmp/output.mp4'.\n",
        "  \"\"\"\n",
        "  num_frames = len(frames)\n",
        "  labels = np.zeros((num_frames))\n",
        "  start, end = np.clip([start, end], 0, num_frames)\n",
        "  for i in range(start, end):\n",
        "    labels[i] = int(np.ceil(count * (i-start) / (end - start)))\n",
        "\n",
        "  signal_2d = np.tile(np.expand_dims(labels, axis=0), [32, 1])\n",
        "\n",
        "  fig, axs = plt.subplots(2, 1,\n",
        "                          figsize=(5,5),\n",
        "                          gridspec_kw={'height_ratios': [1, 10]})\n",
        "\n",
        "\n",
        "  frames = mpy.resize_video(frames, (320, 320))\n",
        "  im = axs[1].imshow(frames[0])\n",
        "  axs[1].set_title(desc, fontsize=16)\n",
        "  axs[1].set_xticks([])\n",
        "  axs[1].set_yticks([])\n",
        "  axs[0].imshow(signal_2d*2, cmap='GnBu')\n",
        "  red_dot, = axs[0].plot([], [], 'ro')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.axis('off')\n",
        "  plt.grid(False)\n",
        "\n",
        "  def update_count_plot(i):\n",
        "    \"\"\"Updates the count and frame in plot.\"\"\"\n",
        "    im.set_data(frames[i])\n",
        "    red_dot.set_data([i], [16])\n",
        "    axs[0].set_xticks([])\n",
        "    axs[0].set_yticks([])\n",
        "\n",
        "\n",
        "  anim = FuncAnimation(\n",
        "      fig,\n",
        "      update_count_plot,\n",
        "      frames=np.arange(1, num_frames),\n",
        "      interval=30,\n",
        "      blit=False,\n",
        "  )\n",
        "  anim.save(output_file, dpi=100, fps=24)\n",
        "  fig.clear()\n",
        "  plt.close(fig)\n",
        "  plt.close()\n",
        "  mpy.show_video(mpy.read_video('/tmp/output.mp4'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdMyoE7ChNy7"
      },
      "source": [
        "# Download OVR Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3e6q0TwbzPw"
      },
      "outputs": [],
      "source": [
        "PATH_TO_KINETICS_ANNOTATIONS = \"https://storage.googleapis.com/semantic_repetitions/ovr_kinetics_release.json\"\n",
        "PATH_TO_EGO4D_ANNOTATIONS = \"https://storage.googleapis.com/semantic_repetitions/ovr_ego4d_release.json\"\n",
        "\n",
        "!wget -q  $PATH_TO_KINETICS_ANNOTATIONS $PATH_TO_EGO4D_ANNOTATIONS\n",
        "\n",
        "PATH_TO_KINETICS_700_2020_ANNOTATIONS_TRAIN = \"https://s3.amazonaws.com/kinetics/700_2020/annotations/train.csv\"\n",
        "PATH_TO_KINETICS_700_2020_ANNOTATIONS_VAL = \"https://s3.amazonaws.com/kinetics/700_2020/annotations/val.csv\"\n",
        "PATH_TO_KINETICS_700_2020_ANNOTATIONS_TEST = \"https://s3.amazonaws.com/kinetics/700_2020/annotations/test.csv\"\n",
        "\n",
        "\n",
        "!wget -q $PATH_TO_KINETICS_700_2020_ANNOTATIONS_TRAIN $PATH_TO_KINETICS_700_2020_ANNOTATIONS_VAL $PATH_TO_KINETICS_700_2020_ANNOTATIONS_TEST\n",
        "\n",
        "dfs = []\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  dfs.append(pd.read_csv(f\"{split}.csv\"))\n",
        "df = pd.concat(dfs)\n",
        "df = df.set_index('youtube_id')\n",
        "\n",
        "with open('ovr_kinetics_release.json') as f:\n",
        "  kinetics_data = json.load(f)\n",
        "\n",
        "with open('ovr_ego4d_release.json') as f:\n",
        "  ego4d_data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkx6wl6_kQl_"
      },
      "source": [
        "# Kinetics Explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEfP9w6oO9T-"
      },
      "outputs": [],
      "source": [
        "# @title Kinetics Specific Functions\n",
        "\n",
        "def download_kinetics_video(\n",
        "    video_id: str,\n",
        "    start_time: float,\n",
        "    end_time: float,\n",
        "    output_path: str = '/tmp/video.mp4',\n",
        "    fps: int = 25\n",
        ") -\u003e None:\n",
        "  \"\"\"\n",
        "  Downloads a specific segment of a Kinetics video from YouTube using youtube-dl\n",
        "   and ffmpeg.\n",
        "\n",
        "  Args:\n",
        "    video_id: The YouTube video ID.\n",
        "    start_time: The start time of the segment to download (in seconds).\n",
        "    end_time: The end time of the segment to download (in seconds).\n",
        "    output_path: The path to save the downloaded video. Defaults to\n",
        "    '/tmp/video.mp4'.\n",
        "    fps: The desired frame rate of the downloaded video. Defaults to 25.\n",
        "  \"\"\"\n",
        "  duration = end_time - start_time\n",
        "  os.system(\"ffmpeg\" + \" -y \" +\n",
        "            f\"-ss {start_time}\" +\n",
        "            \" -i $(youtube-dl -f 18 --get-url \" +\n",
        "            f\"https://youtube.com/v/{video_id}\" +\n",
        "            f\") -t {duration} -c:v libx264 -r {fps} -vsync 0 {output_path}\")\n",
        "\n",
        "\n",
        "def get_random_ovrc_kinetics_video(\n",
        "    anno_list: List[Dict[str, Any]],\n",
        "    visualize_only_repetition: bool,\n",
        "    tmp_output_path: str = '/tmp/output.mp4',\n",
        "    fps: int = 25\n",
        ") -\u003e None:\n",
        "  \"\"\"\n",
        "  Fetches a random video from the Kinetics dataset with repetition annotations,\n",
        "  downloads the relevant segment, and optionally visualizes only the repetition.\n",
        "\n",
        "  Args:\n",
        "    anno_list: A list of dictionaries containing annotation data for Kinetics\n",
        "      videos.\n",
        "    visualize_only_repetition: If True, only the repetition segment is\n",
        "    visualized. If False, the entire video with a count overlay is shown.\n",
        "    tmp_output_path: The temporary path to save the downloaded video. Defaults\n",
        "      to '/tmp/output.mp4'.\n",
        "    fps: The frame rate to use for video processing. Defaults to 25.\n",
        "  \"\"\"\n",
        "  DELTA = 10  # All Kinetics videos are 10s long.\n",
        "\n",
        "  if os.path.exists(tmp_output_path):\n",
        "    os.remove(tmp_output_path)\n",
        "  random_anno = np.random.choice(anno_list)\n",
        "  yt_id = random_anno['video_id']\n",
        "  if yt_id not in df.index:\n",
        "    print(f\"Video {yt_id} not found in Kinetics annotations. Possibly deleted.\")\n",
        "    return\n",
        "  yt_clip_start_time = df.loc[yt_id]['time_start']\n",
        "  random_anno = np.random.choice(random_anno['ovr_annotations'])\n",
        "\n",
        "  download_kinetics_video(yt_id,\n",
        "                          yt_clip_start_time,\n",
        "                          yt_clip_start_time + DELTA,\n",
        "                          tmp_output_path, fps=fps)\n",
        "  if os.path.exists(tmp_output_path):\n",
        "    frames = mpy.read_video(tmp_output_path)\n",
        "  else:\n",
        "    print(f\"Failed to get video {yt_id} at this time.\")\n",
        "    return\n",
        "  start_idx = int(fps * random_anno['start_time'])\n",
        "  end_idx = int(fps * random_anno['end_time'])\n",
        "\n",
        "  if visualize_only_repetition:\n",
        "    mpy.show_video(frames[start_idx:end_idx],\n",
        "                 title=f\"Count: {random_anno['count']},\"\n",
        "                       f\"Desc: {random_anno['description']}\")\n",
        "  else:\n",
        "    create_count_video(frames,\n",
        "                       start_idx,\n",
        "                       end_idx,\n",
        "                       random_anno['count'],\n",
        "                       random_anno['description'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6tLNcp_PTNW"
      },
      "outputs": [],
      "source": [
        "# @title Visualize samples from OVRC-Kinetics dataset.\n",
        "num_videos = 10 # @param {type:\"slider\", min:1, max:25, step:1}\n",
        "visualize_only_repetition = False # @param {type:\"boolean\"}\n",
        "for _ in range(num_videos):\n",
        "  get_random_ovrc_kinetics_video(kinetics_data, visualize_only_repetition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejwYyT2fhkkn"
      },
      "source": [
        "# Ego4D Explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwKceoc65Ztu"
      },
      "outputs": [],
      "source": [
        "# Configure using your Ego4D credentials  (https://ego4d-data.org/docs/start-here/)\n",
        "# Get AWS Access Key ID and AWS Secret Access Key to access Ego4D data.\n",
        "!aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb1BCXkm8P4k"
      },
      "outputs": [],
      "source": [
        "# @title Ego4D Functions\n",
        "\n",
        "def download_ego4d_video(\n",
        "  video_id: str,\n",
        "  start_time: float,\n",
        "  end_time: float,\n",
        "  output_path: str = '/tmp/video.mp4',\n",
        "  fps: int = 30\n",
        ") -\u003e None:\n",
        "  \"\"\"\n",
        "  Downloads a specific segment of an Ego4D video using the ego4d CLI and ffmpeg.\n",
        "\n",
        "  Args:\n",
        "    video_id: The unique identifier of the Ego4D video.\n",
        "    start_time: The start time of the segment to download (in seconds).\n",
        "    end_time: The end time of the segment to download (in seconds).\n",
        "    output_path: The path to save the downloaded video. Defaults to\n",
        "      '/tmp/video.mp4'.\n",
        "    fps: The desired frame rate of the downloaded video. Defaults to 30.\n",
        "  \"\"\"\n",
        "  os.system(f'ego4d -y -o /tmp/ego4d --dataset full_scale --video_uids {video_id}')\n",
        "  duration = end_time - start_time\n",
        "  os.system(\"ffmpeg\" + \" -y \" + f\"-ss {start_time}\" +\n",
        "            f\" -i /tmp/ego4d/v2/full_scale/{video_id}.mp4  -t {duration}\" +\n",
        "            f\"-c:v libx264 -r {fps} -vsync 0 {output_path}\")\n",
        "  os.system(f\"rm -rf /tmp/ego4d/v2/full_scale/{video_id}.mp4\")\n",
        "\n",
        "\n",
        "def get_random_ovrc_ego4d_video(\n",
        "  anno_list: List[Dict[str, Any]],\n",
        "  visualize_only_repetition: bool,\n",
        "  tmp_output_path: str = '/tmp/output.mp4',\n",
        "  fps: int = 30\n",
        ") -\u003e None:\n",
        "  \"\"\"\n",
        "  Fetches a random video from the Ego4D dataset with repetition annotations,\n",
        "  downloads the relevant segment, and optionally visualizes only the repetition.\n",
        "\n",
        "  Args:\n",
        "    anno_list: A list of dictionaries containing annotation data for Ego4D\n",
        "      videos.\n",
        "    visualize_only_repetition: If True, only the repetition segment is\n",
        "      visualized. If False, the entire video with a count overlay is shown.\n",
        "    tmp_output_path: The temporary path to save the downloaded video. Defaults\n",
        "      to '/tmp/output.mp4'.\n",
        "    fps: The frame rate to use for video processing. Defaults to 30.\n",
        "  \"\"\"\n",
        "  DELTA = 10 + 2/fps\n",
        "  # Random annotation sampling.\n",
        "  if os.path.exists(tmp_output_path):\n",
        "    os.remove(tmp_output_path)\n",
        "  random_anno = np.random.choice(anno_list)\n",
        "  video_id = random_anno['video_id']\n",
        "\n",
        "  clip_start_time = random_anno['timestamp_sec']\n",
        "  random_anno = np.random.choice(random_anno['ovr_annotations'])\n",
        "\n",
        "  download_ego4d_video(video_id,\n",
        "                       max(0, clip_start_time - DELTA/2),\n",
        "                       clip_start_time + DELTA/2,\n",
        "                       tmp_output_path,\n",
        "                       fps=fps)\n",
        "  # Visualize whole clip including non-repeating part.\n",
        "  if os.path.exists(tmp_output_path):\n",
        "    frames = mpy.resize_video(mpy.read_video(tmp_output_path),\n",
        "    (640, 360))\n",
        "  else:\n",
        "    print(f\"Failed to download video {video_id}\")\n",
        "    return\n",
        "  start_idx = int(fps * random_anno['start_time'])\n",
        "  end_idx = int(fps * random_anno['end_time'])\n",
        "\n",
        "  if visualize_only_repetition:\n",
        "    mpy.show_video(frames[start_idx:end_idx],\n",
        "                 title=f\"Count: {random_anno['count']},\"\n",
        "                 f\"Desc: {random_anno['description']}\")\n",
        "  else:\n",
        "    create_count_video(frames,\n",
        "                       start_idx,\n",
        "                       end_idx,\n",
        "                       random_anno['count'],\n",
        "                       random_anno['description'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqvrhlyJME62"
      },
      "outputs": [],
      "source": [
        "# @title Visualize samples from OVRC-Ego4D dataset.\n",
        "num_videos = 10 # @param {type:\"slider\", min:1, max:25, step:1}\n",
        "visualize_only_repetition = False # @param {type:\"boolean\"}\n",
        "for _ in range(num_videos):\n",
        "  get_random_ovrc_ego4d_video(ego4d_data, visualize_only_repetition)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//gdm/robotics/flexcap/colab:flexcap_labeling_colab",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "19XGDOSXwVxQxe5ihetvShI4IdEt9m6Ce",
          "timestamp": 1721806246063
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
